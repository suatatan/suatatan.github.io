---
title: "Daily Academic Writing Journal: Yapay Zeka ve Metin MadenciliÄŸi AraÅŸtÄ±rma NotlarÄ±"
description: "Dr. Suat ATAN'Ä±n akademik araÅŸtÄ±rma gÃ¼nlÃ¼ÄŸÃ¼: LLM modelleri, BERT, GPT, text mining, machine learning ve veri analizi Ã¼zerine gÃ¼nlÃ¼k notlar ve keÅŸifler."
keywords: "akademik araÅŸtÄ±rma, yapay zeka, LLM, BERT, GPT, text mining, machine learning, veri analizi, araÅŸtÄ±rma gÃ¼nlÃ¼ÄŸÃ¼, AI research"
author: "Dr. Suat ATAN"
date: 2025-06-19
layout: post
lang: tr
image: "/images/social-preview.svg"
categories:
- araÅŸtÄ±rma
- yapay-zeka
tags: 
  - turkish
  - text-mining
  - machine-learning
  - local-agenda
  - news-analysis
  - clustering
  - classification
  - akademik-araÅŸtÄ±rma
  - yapay-zeka
  - LLM
  - BERT
  - GPT
---

# Daily Academic Writing Journal: Yapay Zeka ve Metin MadenciliÄŸi AraÅŸtÄ±rma NotlarÄ±

**Bu gÃ¼nlÃ¼k, akademik araÅŸtÄ±rmalarÄ±m sÄ±rasÄ±nda okuduÄŸum makalelerden, kitaplardan ve kaynaklardan aldÄ±ÄŸÄ±m notlarÄ± iÃ§erir. [Yapay zeka](/tag/yapay-zeka), [metin madenciliÄŸi](/tag/text-mining) ve [machine learning](/tag/machine-learning) alanlarÄ±ndaki gÃ¼ncel geliÅŸmeleri takip etmek iÃ§in dÃ¼zenli tuttuÄŸum notlar.**

> **ğŸ“š AraÅŸtÄ±rma Metodu**: Bu notlar, **LLM modelleri**, **BERT**, **GPT** aileleri ve **text mining** teknikleri Ã¼zerine sÃ¼rdÃ¼rdÃ¼ÄŸÃ¼m akademik Ã§alÄ±ÅŸmalarÄ±n bir parÃ§asÄ±dÄ±r. Her entry, o gÃ¼nkÃ¼ okuma ve araÅŸtÄ±rmalarÄ±mÄ±n Ã¶zeti niteliÄŸindedir.

> **ğŸ”— Ä°lgili YazÄ±lar**: [Teknoloji](/tag/teknoloji) ve [deepresearch](/tag/deepresearch) kategorilerindeki diÄŸer makalelerimde bu konularÄ± daha detaylÄ± iÅŸliyorum.

# 04.01.2024

https://media.licdn.com/dms/document/media/D4D1FAQHnl1D48w8Mhw/feedshare-document-pdf-analyzed/0/1703616547966?e=1704931200&v=beta&t=HRRsT9gaQDViCm5VabgL7lan5hozK0CR4EtGLqhCmHg


Sinan Ã–zdemir'in LLM kitabÄ±ndan. Autoencoding LLM modelleri boÅŸluk doldurmaya yarar.  Ã–rnek BERT. Autoregressive modeller ise sonraki gelecek kelime veya cÃ¼mleye odaklanÄ±r.  Gpt3 175B 570GB eÄŸitim datasÄ±na ihtiyaÃ§ duyar. Modelin kendisi 700GB yer kaplar. Ama Bert training iÃ§in 20GB diskte model iÃ§in 1GB alana ihtiyaÃ§ duyar.

Transformers'daki encoder sol taraf yani metni anlamaya yarar. Metni alÄ±p kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼p encode eder. Sonra da saÄŸ taraf da metin Ã¼retir. Ä°Ã§teki katmanlar daha Ã§ok optimizayson vs. iÃ§indir. Bu iki model yani encoder ve decoder bir araya gelince seq2seq modeli olmuÅŸ olur.

Autoregressive modeller metin yazma iÃ§in iyi iken audoencoding modeller  (BERT gibi) metin sÄ±nÄ±flandÄ±rmaya iyidir.

Ä°kisinin miksi olan T5 modeli vardÄ±r. Bu hem metin Ã¼retme hem de metin sÄ±nÄ±flandÄ±rma iÃ§in eÄŸitilebilir.

bu onlarÄ± daha gÃ¼Ã§lÃ¼ kÄ±lar. GPT ailesi decoder only dÄ±r.

BERT Wiliedpai ve BookCorpus ile eÄŸitilmiÅŸtir.

Sayfa 26 note kÄ±smÄ±na kadar geldÄ±m.


# 11.11.2021
Scraping with Python kitabÄ±nda iki yeni bilgi

Ponti: GÃ¶rsel scraping olayÄ±
Scrapely: Makine Ã¶ÄŸrenmesi ile farklÄ± sitelerden scraping yapabilme opsiyonu
Scra.py: En hÄ±zlÄ± scraper ama bloklama ihtimali var.

# 04.11.2021

Scraping with Python kitabÄ±nÄ± okuyorum. KazÄ±nan dosyalar sisteme kaydedilmek yerine Redis'e kaydedilmeli. Redis direkt key value sistem. Servis olarak Ã§alÄ±ÅŸÄ±r.
AynÄ± kitapta bu iÅŸlem iÃ§in hazÄ±r bir
Python kÃ¼tÃ¼phanesi olduÄŸunu Ã¶ÄŸrendim. requests-cache
Bu sayfalarÄ± indiriyor, cache de varsa indirmiyor. DiÄŸer yandan redis mongo ve sqlite ile Ã§alÄ±ÅŸÄ±yor.

Ã‡ok. sayfa varsa bu durumda paralel download mÃ¼mkÃ¼n
EÄŸer ayrÄ± ayrÄ± domainde sayfa varsa ve Ã§oksa sÄ±rayla
Ã‡ekmek yerine paralel harika olur delaya da gerek kalmaz

Paralel yÃ¶ntem 1: multithreading: iÅŸlemci a URLsini indirirken yavaÅŸlama veya durma olursa baÅŸka bir thread bekleme yapmadan kuyrukta baÅŸka URL i alÄ±r

# 05.05.2020

son kaldÄ±ÄŸÄ±m sayfa: 5

**Antons, D., GrÃ¼nwald, E., Cichy, P., & Salge, T. O. (2020). The application of text mining methods in innovation research: Current state, evolution patterns, and development priorities. R and D Management. https://doi.org/10.1111/radm.12408**

GrÃ¼nwald ve arkadaÅŸlarÄ± Ã§alÄ±ÅŸmalarÄ±nda metin madenciliÄŸinin Ã¶zel bir kullanÄ±m alanÄ±ndan sÃ¶z etmektedir: Metin madenciliÄŸi ile inovasyon araÅŸtÄ±rmalarÄ±.  Ä°novasyonun metin madenciliÄŸi ile takip edebileceÄŸine gÃ¶nderme yapan bu literatÃ¼r bahse konu  Ã§alÄ±ÅŸmada taranmÄ±ÅŸtÄ±r.

>124 adet dergi taranmÄ±ÅŸtÄ±r bu dergilerden 10'u premier "innovation management" dergisidir. Buradan ÅŸunu anlÄ±yorum. Ä°novasyon yÃ¶netimi diye alt bir alan var.

**Metin madenciliÄŸi kelime sÄ±klÄ±klarÄ±na dayalÄ±dÄ±r**: Text mining techniques that rely on word frequency counts to measure contextual, psychological, linguistic, or semantic concepts and constructs are among the most widely adopted approaches for computer-aided analysis of textual data in management related research so far (Duriau et al., 2007; Short et al., 2010).

**LiteratÃ¼r review'in de bir yÃ¶ntemi vardÄ±r:** To provide scholars with a structured overview of the state and evolution of text mining application in the field of innovation research, we conducted a systematic literature review (Mulrow, 1994; Tranfield et al., 2003; Denyer and Tranfield, 2009). We proceeded in the following way.

LiteratÃ¼r review'in nasÄ±l yapÄ±lacaÄŸÄ±na dair makaleler:

- Mulrow, C.D. (1994) Systematic reviews: rationale for systematic reviews

Ä°novasyon yÃ¶netimi ile ilgili bulduÄŸu en Ã¶nemli dergiler (ileride makale yollanabilir)

- (1) Research Policy, 
- (2) Journal of Product
- (3) R&D Management,
- (4) Technological Forecasting and SocialChange, 
- (5) Research-Technology Management,
- (6) Technovation, 
- (7) Industrial and Corporate Change, 
- (8) IEEE Transactions on EngineeringManagement, 
- (9) the Journal of TechnologyTransfer
- (10) the Journal of Engineering andTechnology Management. 

**Bu Ã§alÄ±ÅŸmada izlenen literatÃ¼r tarama metodu**

- En etkili dergileri seÃ§ (yukarÄ±da)
- Bu dergilerde Ã¶nceden aÃ§Ä±kÃ§a belirlenmiÅŸ anahtar terimlerle arama yap (adam bunu makale ekine koymuÅŸ) Bu Ã§alÄ±ÅŸma iÃ§in iÃ§in anahtar terimlerinde  text mining, sentiment analysis geÃ§en makaleleri listelemiÅŸ
- Bu ÅŸekildeki tÃ¼m makaleleri indirmiÅŸ ancak ilgili olmayanlarÄ± elle elemiÅŸ. (Text mining'de sen de kullanabilirsin)
- Ortada farklÄ± dergilerden 124 makale kalmÄ±ÅŸ
- We applied a combination of bibliometric analysis and manual coding (Alta bak)
- Makale kategorileri belirle (bu Ã§alÄ±ÅŸmada R iÃ§in uygulama makaleleri, reviewler ve tanÄ±tÄ±m makaleleri olarak belirlenmiÅŸ)
- 

**Bibliyometrik Ã§alÄ±ÅŸmalar iÃ§in R paketi**
>As for the bibliometric analyses, the R-package â€˜bibliometrixâ€™ was used. The package provides several tools for quantitative research models in bibliometrics and scientometrics. The functional scope includes importing and formatting of raw data, the actual bibliometric analyses, as well as the creation of matrices and networks for the visualization of co-citations, couplings, collaborations, and co-work analyses. 

**Bibliyometrik Ã§alÄ±ÅŸmalar iÃ§in R verisi**
> After importing the data from the Web Of Science in BibTex format, we used the individual
meta-information to extract the author keywords and to build a co-occurrence network. Subsequently, adopting the Louvain-clustering method, we visualized the distribution and grouping of the author keywords.

**Ã‡oÄŸu metin madenciliÄŸi Ã§alÄ±ÅŸmasÄ± makaleleri analiz eder, ikinci de patentler vardÄ±r**

>With regard to the type of textual data analyzed, we found that 48 articles investigate research papers and 44 analyze patents. Less frequently studied are texts like blog posts and forum entries (12), newspaper articles (7), tweets and other social media entries (5), and product reviews (3). Other texts like annual reports, emails, press releases, interviews have each only been analyzed once. Interestingly, we find a broad variability with regard to the amount of texts that have been used. Of the 124 articles, 58.9% use less than 10,000 texts, 22.6% use more than 10,000 but less than 100,000 documents, 4.8% analyze more than 100,000 but less than 1,000,000 texts, and 13.7% investigate even more than 1,000,000 texts.

## Bu makale ile daha Ã¶nceden hiÃ§ bilmeyip Ã¶ÄŸrendiÄŸim ÅŸeyler

- LiteratÃ¼r taramasÄ±nÄ±n nasÄ±l olacaÄŸÄ±na dair makaleler vardÄ±r.
- Bu Ã§alÄ±ÅŸma ile literatÃ¼rÃ¼ nasÄ±l tarayacaÄŸÄ±mÄ± Ã¶ÄŸrendim
- R'da bibliometrix adlÄ± bir kÃ¼tÃ¼phane vardÄ±r ve bu kÃ¼tÃ¼phane ile bir Ã§ok bibliyometrik analiz gerÃ§kleitirilebilir
- Web of science'den bibliyometrik veri indirilerek analiz yapÄ±labilmektedir.
- Adam 124 makalelik koleksiyonuna da corpus demiÅŸ
- Metin madenciliÄŸi ile ilgili Ã§alÄ±ÅŸmalarda 2015 yÄ±lÄ±ndan sonra ciddi artÄ±ÅŸ olmuÅŸtur

## Yeni Makale Fikirleri

- TÃ¼rkÃ§e literatÃ¼rde inovasyon araÅŸtÄ±rmalarÄ±na dair literatÃ¼r taramasÄ±. Bu makale Ã§ok iyi olabilir. Ã–zelliklÅŸe [ÅŸuradaki](https://bibliometrix.org/screenshots/index.html) ekran gÃ¶rÃ¼ntÃ¼lerinden yapÄ±labilecek Ã§alÄ±ÅŸmalar Ã§ok heyecan verici gÃ¶zÃ¼kÃ¼yor. AyrÄ±ca TTGV iÃ§in de iÅŸe yarayabilir. Ya da ticarileÅŸtirilebilir. Ã–zellikle Ã¼lkeler arasÄ± collaboration harika bir harita sunmakta


# 04.05.2020

Using Machine Learning to Measure Changes in Cable News Coverage of Immigration (2014-2019). (t.y.). Microsoft Social Sciences. https://doi.org/microsoft_corporation.25104.1106

Bu makale metin madenciliÄŸi ile gÃ¶Ã§menler hakkÄ±nda Trump'un gÃ¶reve baÅŸlama konuÅŸmasÄ±ndan sonra ortaya Ã§Ä±kan haberleri ve tarihi ele alÄ±yor

# 20.02.2020 - Kmeans

**Dunn indeksi** elde edilen kÃ¼meler arasÄ±ndaki uzaklÄ±ÄŸÄ± da dikkate alan bir Ã¶lÃ§Ã¼ttÃ¼r.  DoÄŸal olarak bu deÄŸer ne kadar bÃ¼yÃ¼k olursa kÃ¼melerin birbirinden o  kadar uzakta olduÄŸu anlaÅŸÄ±lacaktÄ±r. Bu durumda K-Means algoritmasÄ±nÄ±n daha ayrÄ±ÅŸtÄ±rÄ±cÄ± ve net olduÄŸu ortaya Ã§Ä±kar. 
Dunn indeksi *inter-cluster distance* yahut kÃ¼meler arasÄ± uzaklÄ±k olarak da adlandÄ±rÄ±lmaktadÄ±r.  FormÃ¼lÃ¼ ise Intertia indeksine gÃ¶re bir derece daha karmaÅŸÄ±k bir formÃ¼ldÃ¼r. Intertia deÄŸerinde bir kÃ¼meye ait aÄŸÄ±rlÄ±k merkezi ile Ã§evresindeki yakÄ±n noktalara olan uzaklÄ±k toplamÄ± Ã¶nceki formÃ¼lde olduÄŸu gibi $Ig$ iken Interia deÄŸeri tÃ¼m kÃ¼melere ait deÄŸerler toplamÄ± idi $\Sigma I_g$, burada tÃ¼m $I_g$ deÄŸerlerinin en kÃ¼Ã§Ã¼ÄŸÃ¼ $min(I_g)$ olsun. Bir kÃ¼menin $g_i$ diÄŸer  kÃ¼me $g_j$ ile arasÄ±ndaki  uzaklÄ±k ise $E_{g_i,g_j}$olsun. Bu deÄŸerlerin en bÃ¼yÃ¼ÄŸÃ¼ de $min(E_{g_i,g_j})$ olarak gÃ¶sterilsin. Bu durumda Dunn indeksi $D$
$$
D = \frac{max(E_{g_i,g_j})}{min(I_g)}
$$
olacaktÄ±r. Burada tÃ¼m kÃ¼melerin oluÅŸturduÄŸu evrende herhangi iki kÃ¼me arasÄ±ndaki uzaklÄ±k bÃ¼yÃ¼dÃ¼kÃ§e (pay) Dunn indeksi kÃ¼Ã§Ã¼lecektir. Inertia deÄŸeri de kÃ¼Ã§Ã¼ldÃ¼ÄŸÃ¼nde Dunn Indeksi bÃ¼yÃ¼r. Yani kÃ¼meler arasÄ± ayrÄ±ÅŸÄ±m daha net hale gelir.

**Peki bu deÄŸerleri ne iÃ§in kullanÄ±rÄ±z?** 

En baÅŸta gÃ¶zetimsiz algoritmalardan biri olan K-means algoritmasÄ±nÄ±n dÄ±ÅŸarÄ±dan aldÄ±ÄŸÄ± tek deÄŸerin $k$ adet kÃ¼me deÄŸeri olduÄŸunu ele almÄ±ÅŸtÄ±k. Bu durumda eldeki verilerin iÃ§eriÄŸindeki kÃ¼me adedinin bilinmediÄŸi durumlarda yanlÄ±ÅŸ $k$Â deÄŸerinin analiz sonuÃ§larÄ±nÄ± yanÄ±ltacaÄŸÄ± aÃ§Ä±ktÄ±r. Ä°ÅŸte bu durumlarda yukarÄ±daki iki Ã¶lÃ§Ã¼t en uygun $k$ deÄŸerini bulmak iÃ§in kullanÄ±labilir. BÃ¶yle bir durumda $k=2$ deÄŸerinden baÅŸlanarak K-Means algoritmasÄ± ile kÃ¼meleme analizi yapÄ±ltÄ±ktan sonra   Inertia deÄŸeri hesaplanÄ±r, daha sonra $k$ deÄŸeri arttÄ±rÄ±larak aynÄ± Ã¶lÃ§Ã¼tler yeniden hesaplanÄ±r ve bu istenen $k$Â miktarÄ±na kadar devam edilir. Bu durumda ortaya Ã§Ä±kan Inertia deÄŸerlerinin en kÃ¼Ã§Ã¼k olduÄŸu $k$ deÄŸeri (ya da deÄŸerlerinden biri) seÃ§ilerek bu deÄŸer doÄŸru kabul edilir ve bu $k$ deÄŸerine gÃ¶re Ã¼retilmiÅŸ kÃ¼meler artÄ±k veri setindeki kayÄ±tlarÄ±n etiketleri olarak ele alÄ±nÄ±r.



#  19.02.2020 - KMeans

GÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere K-Means algoritmasÄ± dÄ±ÅŸarÄ±dan herhangi bir eÄŸitim verisi almamakta sadece $k$ olarak belirtilen ortaya Ã§Ä±karÄ±lacak kÃ¼me sayÄ±sÄ±nÄ± almakadÄ±r. Bir algoritmanÄ±n *gÃ¶zetimsiz* algoritma olarak nitelendirilme nedeni budur. Ancak $k$ deÄŸerinin belirlenmesi zorunludur. Normalde Ã¶rneÄŸin iÃ§eriÄŸinde kredi Ã¶rneÄŸinde olduÄŸu gibi *borcunu Ã¶deyenler* ve *Ã¶demeyenler* ÅŸeklinde iki grubun olacaÄŸÄ± Ã¶nceden biliniyorsa zaten iki grup olduÄŸundan $k=2$ denecektir. Peki, grup sayÄ±sÄ±nÄ±n bilinmediÄŸi durumlarda ne yapÄ±lmalÄ±dÄ±r? Ä°ÅŸte bu durumda rastgele bir $k$ sayÄ±sÄ± seÃ§ilebilir ancak bu gerÃ§ekÃ§i olmayÄ±p aslÄ±nda daha fazla sayÄ±da grup varsa gruplarÄ±n birleÅŸmesine, daha az sayÄ±da grup varsa aslÄ±nda olmayan gruplarÄ±n varmÄ±ÅŸ gibi ortaya Ã§Ä±kmasÄ±na neden olabilir. Ancak $k$ deÄŸerinin optimal bir deÄŸeri vardÄ±r ve bu deÄŸer seÃ§ildiÄŸi takdirde gerÃ§ek veya ona en yakÄ±n sayÄ±daki kÃ¼meler belirlenebilir. Bu optimal $k$ deÄŸerinin hesaplanabilmesi iÃ§in K-Means algoritmasÄ±nÄ±n iki temel Ã¶lÃ§Ã¼tÃ¼nden sÃ¶z etmek gerekir.

**Inertia DeÄŸeri:** K-Means algoritmasÄ± tarafÄ±ndan bulunan gruplardaki her bir noktanÄ±n  bu grubun aÄŸÄ±rlÄ±k merkezi olan  ($c_1, c_2$ gibi) noktaya uzaklÄ±klarÄ±nÄ±n toplam deÄŸeridi o grup iÃ§in $I_g$ olsun. Bu deÄŸer tÃ¼m kÃ¼meler iÃ§in hesaplanÄ±r ve genel toplam alÄ±nÄ±r $ \Sigma I_{g}$. Bu deÄŸerin kÃ¼Ã§Ã¼k olmasÄ± tercih edilir nitekim gruptaki noktalar aÄŸÄ±rlÄ±k merkezine ne kadar yakÄ±nda o kÃ¼medeki noktalarÄ±n o kadar benzer sÄ±nÄ±fta olduÄŸu kabul edilir. Bu *inertia* deÄŸeri "kÃ¼me iÃ§i uzaklÄ±k" ya da *intra cluster distance* olarak da bilinmektedir.

Inertia deÄŸeri her bir kÃ¼menin kendi iÃ§inde aÄŸÄ±rlÄ±k merkezi ile grup iÃ§indeki noktalarÄ±n arasÄ±na odaklanmakla kÃ¼melerin kendi aralarÄ±ndaki uzaklÄ±klarÄ± gÃ¶z ardÄ± etmektedir. EÄŸer iki kÃ¼me arasÄ±nda mesafe Ã§ok yakÄ±n ise kÃ¼Ã§Ã¼k intertia deÄŸerine raÄŸmen bazÄ± noktalarÄ±n (ara bÃ¶lgelerde) hangi kÃ¼meye ait olduÄŸu net olmayabilir. 

TODO: Opsiyonal: Bir Ã¶rnek verebilirsin yakÄ±n kÃ¼melere

Bu durumda kÃ¼meler arasÄ± uzaklÄ±ÄŸÄ± da maksimize edecek bir deÄŸer daha vardÄ±r. Dunn Index

# 18.02.2020 - KMeans

 TODO: Bir grafik, yaÅŸ eÄŸitim ve kredi Ã¶deme ile ilgili. YaÅŸlÄ± ve yÃ¼ksek eÄŸitimliler mavi ile iÅŸaretlenecek saÄŸda onlar kredisini Ã¶dÃ¼yor

K-Means algoritmasÄ±n ÅŸekli yukarÄ±daki gibi basit bir Ã¶rnekle aÃ§Ä±klanabilir. Bu Ã¶rnekte sadece iki parametre sÃ¶z konusu olduÄŸundan veriler grafiÄŸe dÃ¶kÃ¼ldÃ¼ÄŸÃ¼nde kÃ¼meler kolayca gÃ¶rÃ¼lebilmektedir. ÃœÃ§ boyutlu olarak da bu durum gÃ¶rsel hale getirilebilir ve kÃ¼meler gÃ¶rÃ¼lebilir ancak daha fazla boyutta yani daha fazla parametrenin sÃ¶z konusu olmasÄ± halinde gÃ¶rselleÅŸtirilme sÃ¶z konusu deÄŸildir. Bu nedenle kÃ¼melerin sayÄ±sal olarak bulunmasÄ± gerekir. K-Means algoritmasÄ± bu kÃ¼meleri ÅŸu ÅŸekilde bulmaktadÄ±r.

AdÄ±m 1: Ã–ncelikle kaÃ§ adet kÃ¼me bulunacaÄŸÄ±na ($k$) karar verilir. 

AdÄ±m 2: Daha sonra her bir olasÄ± kÃ¼me iÃ§erisindeki noktalardan  tesadÃ¼fi bir nokta ya da aÄŸÄ±rlÄ±k merkezi (centroid) seÃ§ilir. Bu sayÄ± en $k$ sayÄ±sÄ± kadar olmalÄ±dÄ±r.

AdÄ±m 3: Ä°lk belirlenen her bir aÄŸÄ±rlÄ±k merkezine en yakÄ±n noktalar bir kÃ¼me olarak iÅŸaretlenir. Ã–rneÄŸin  $k=2$ olduÄŸu durumda iki aÄŸÄ±rlÄ±k merkezi ve $k_1$ ve $k_2$ noktalarÄ±dÄ±r. $k_1$ aÄŸÄ±rlÄ±k merkezine en yakÄ±n noktalar grubu $g_1$, $k_2$ aÄŸÄ±rlÄ±k merkezine en yakÄ±n noktalar grubu ise $g_2$ olarak iÅŸaretlenir.

AdÄ±m 4: Her bir grubun koordinat sistemindeki aÄŸÄ±rlÄ±k merkezi yeniden hesaplanÄ±r. Bu ilk hesaplamadaki aÄŸÄ±rlÄ±k merkezi her bir grup iÃ§in $c_{g_1-i_1}$, $c_{g_2,i_1}$ olarak gÃ¶sterilsin. AÄŸÄ±rlÄ±k merkezi gruptaki her noktaya en yakÄ±n yeri ifade eder. Burada bir nokta olmak zorunda deÄŸildir. Buradaki $i_1, i_2$ ÅŸeklindeki notasyon iterasyon (hesaplama) nosudur.

AdÄ±m 5: Bir Ã¶nceki adÄ±mda hesaplanan aÄŸÄ±rlÄ±k merkezine en yakÄ±n noktalar yeniden gruplanÄ±r. Bu durumda 3. adÄ±mdaki gruplandÄ±rma deÄŸiÅŸebilir. Yani $g_1$ ve $g_2$ grubu  iÃ§indeki noktlalar deÄŸiÅŸebilir. Yeniden gruplandÄ±rma sonrasÄ± AdÄ±m 4'e dÃ¶nÃ¼lÃ¼r ve yeni aÄŸÄ±rlÄ±k merkezleri hesaplanÄ±r bu durumdaki yeni aÄŸÄ±rlÄ±k merkezi $c_{g_1-i_2},c_{g_2-i_2}$ ÅŸeklinde iterasyon sayÄ±sÄ±na gÃ¶re artacaktÄ±r

Bu durum durdurulmadÄ±ÄŸÄ± takdirde AdÄ±m 4 ve AdÄ±m 5 sonsuza kadar sÃ¼rebilir. Ä°ÅŸte tam bu noktada K-means algoritmasÄ±nÄ±n mantÄ±ÄŸÄ± devreye girmekte ve sÃ¼reci bir yerde keserek son tahlilde oluÅŸan gruplarÄ± kÃ¼me olarak kabul etmektedir. Peki algoritma ne zaman duracaktÄ±r?

K-Means algoritmasÄ± Ã¼Ã§ Ã¶zel durumda durur:

Durum 1: Algoritma devam ettiÄŸi halde AdÄ±m 4'teki aÄŸÄ±rlÄ±k merkezlerinin $c_{g_1},c_{g_2}$  yeri artÄ±k yeni hesaplamaya raÄŸmen deÄŸiÅŸmiyorsa.

Durum 2:  Algoritma devam ettiÄŸi halde her iterasyonda gruplar ($ g_1,g_2 $) deÄŸiÅŸmiyorsa.

Durum 3: Algoritma iÃ§in Ã¶nceden belirlenmiÅŸ bir iterasyon sayÄ±sÄ±na eriÅŸildi ise. Ã–rneÄŸin $i=10.000$ olduÄŸunda durum 1 ve durum 2 olmasa dahi algoritma durur.

YukarÄ±da sayÄ±lan durumlarda K-means algoritmasÄ± duracak ve artÄ±k son elde edilen gruplar kÃ¼me kabul edilecektir.

https://app.getpocket.com/read/2696383230

# 13.02.2020 paper-togg

Konu ile ilgili medyada Ã§Ä±kan haberler genellikle olumlu da olsa, bazÄ± kaynaklar ise bu projeyi vadedilen Ã¼retim sÃ¼resinin Ã§ok kÄ±sa olmasÄ±, Hint ve Ã‡in markalarÄ± olan Tata ve Gelly'in tasarÄ±mÄ±nÄ±n dahil tamamÄ±nÄ±n Ã¼retici devletin kaynaklarÄ± ile ortaya Ã§Ä±karÄ±lmasÄ± gibi konularÄ± ele alarak eleÅŸtirmektedirler. Teknik olarak bu tartÄ±ÅŸmalarÄ±n dÄ±ÅŸÄ±nda, konu ile ilgili Ã§Ä±kan her tÃ¼rden haberlerin vurgu yaptÄ±ÄŸÄ± konularÄ±n ne olduÄŸunun incelenmesi araÃ§ hakkÄ±ndaki genel anlayÄ±ÅŸÄ± ve ortaya Ã§Ä±kacak beklentilerin anlaÅŸÄ±lmasÄ±na yardÄ±mcÄ± olabilir.

NOT: GÃ¶zetimsiz algoritmalardan K-Means ve Chi-Square kullanarak olumlu ve olumsuz haberlerde en sÄ±k gÃ¶rÃ¼len kelimeler ve bigramlar ortaya Ã§Ä±karÄ±labilir. Bu sayede haberlerin vurguladÄ±klarÄ± yÃ¶nler anlaÅŸÄ±labilir. Yine otomobili merkeze alan Ã¶zel bir kavramlaÅŸtÄ±rma haritasÄ± Ã¼retilebilir. 

# 05.02.2020 paper-togg

Yerli ve milli olarak ifade edilen TOGG otomobillerle ilgili yayÄ±nlanan haberlerin genel iÃ§eriÄŸinin incelenmesi bu konuda medyanÄ±n yaklaÅŸÄ±mÄ±nÄ± ortaya Ã§Ä±karmak bakÄ±mÄ±ndan faydalÄ±dÄ±r. AyrÄ±ca ilgili araba ile ilgili hangi Ã¶zelliklerin Ã¶ne Ã§Ä±karÄ±ldÄ±ÄŸÄ± hususu da bu analiz neticesinde ortaya Ã§Ä±kacaktÄ±r. DiÄŸer taraftan genellikle olumlu haberler Ã§Ä±kan TOGG iÃ§in olumsuz haberler de analiz edilmiÅŸtir. Olumsuz haberlerin de gÃ¼ndemini belirlemek ve temel noktalarÄ± ortaya Ã§Ä±karmak Ã¶nemlidir. 

# 04.02.2020 free

WordNet, Princeton Ã¼niversitesi tarafÄ±ndan geliÅŸtirilmiÅŸ bir veri tabanÄ±dÄ±r. Bu veri tabanÄ±nda bir kavram ile iliÅŸkili tÃ¼m kavramlar listelenmektedir. EÅŸ anlamlÄ±lÄ±k ve benzeri tÃ¼m iliÅŸkiler bu veri tabanÄ±nda mevcuttur. WordNet aÃ§Ä±k kaynaklÄ± olup herkesin Ã¼cretsiz olarak kullanÄ±mÄ±na aÃ§Ä±ktÄ±r ve her dil iÃ§in versiyonu bulunmaktadÄ±r. Wordnet'te Ã¶rneÄŸin "pencere" kelimesi aratÄ±ldÄ±ÄŸÄ±nda onun "holonym'i" olan "ev" kelimesi ya da "hararet" kelimesinin eÅŸ anlamlÄ±sÄ± olan "sÄ±caklÄ±k" kelimesi gibi tÃ¼m iliÅŸkiler gelir.

WordNet neden Ã¶nemlidir. Ã–zellikle BoW modeli ile analizde sÃ¶z gelimi hava durumu haberleri ile ilgili bir analizde "yaÄŸmur" kavramÄ± en Ã§ok gÃ¶rÃ¼len kavram olsun,  "hararet", "sÄ±caklÄ±k", "Ä±sÄ±" gibi kelimeler de sÄ±rasÄ± ile sÄ±k gÃ¶rÃ¼len diÄŸer kavramlar olsun. Normalde 3,4 ve 5. kavramlarÄ±n her biri sÄ±caklÄ±k ile ilgilidir ve bu kavramlar bir araya getirildiÄŸinde aslÄ±nda en sÄ±k gÃ¶rÃ¼len kavrama dÃ¶nÃ¼ÅŸecektir. Ä°ÅŸte bu durumda WordNet veya benzeri bir yapÄ±nÄ±n Ã¶nemi ortaya Ã§Ä±kar. Burada "hararet", "sÄ±caklÄ±k" ve "Ä±sÄ±" kavramlarÄ± "synset" olarak adlandÄ±rÄ±lÄ±r. Psikolojik olarak insan zihninde aslÄ±nda Ã§ok yakÄ±n bir imgeye iÅŸaret ederler.

# 03.02.2020 free

SIMNET diye bir metot var tam anlamadÄ±m ancak edindiÄŸim izlenim ÅŸu:

Metin madenciliÄŸinde bir Ã§ok yÃ¶ntem kelimelerin varlÄ±ÄŸÄ± veya yokluÄŸuna dayalÄ±dÄ±r. Bu varsayÄ±m, bir dizi farklÄ± metinden oluÅŸan bir kÃ¼mede (korpus) kullanÄ±lan tÃ¼m kelimeler iÃ§in standart bir yazÄ±mÄ±n mevcut olduÄŸunu, yazÄ±m hatalarÄ±nÄ±n ise Ã§ok az olduÄŸu varsayÄ±mÄ±nÄ± gerektirir. Standart metinlerin Ã§oÄŸu iÃ§in bu durum geÃ§erlidir. YazÄ±m hatalarÄ± analize zarar vermeyecek kadar azdÄ±r. Ancak gerek dilin doÄŸasÄ±, gerekse metinleri kaleme alan insanlarÄ±n alÄ±ÅŸkanlÄ±klarÄ± bir olgu farklÄ± kelimeler (eÅŸ anlamlÄ±) ele alÄ±nabilir ya da bu kelimeler kullanÄ±lmaksÄ±zÄ±n ifadeler dolaylÄ± olarak anlatÄ±labilir. Ä°ÅŸte bu tÃ¼r bir durumda metin madenciliÄŸi iÃ§in Ã¶nemli bir zorluk ortaya Ã§Ä±kmaktadÄ±r. GÃ¶zetimli makine Ã¶ÄŸrenmesi olmaksÄ±zÄ±n bu problemlerin kelime sÄ±klÄ±klarÄ±na dayalÄ± olarak Ã§Ã¶zÃ¼mlenmesi Ã§ok zordur.  

Bag of words modeli ÅŸudur:

> The **bag-of-words** (BOW) model is a representation that turns arbitrary text into **fixed-length vectors** by counting how many times each word appears. This process is often referred to as **vectorization**.

Yani BoW metodu aslÄ±nda bir korpusu, dokÃ¼man-terim matrisi olarak adlandÄ±rÄ±lan dikey eksende dokÃ¼manlarÄ± tanÄ±mlayan kimlik bilgisinin (numara, no, seri no vs.), yatay eksende ise kelimelerin (tekrar etmeksizin) yer aldÄ±ÄŸÄ± bir matristir. Bu matristeki her bir hÃ¼cre kesiÅŸim eksenlerindeki dokÃ¼man-kelime ikilisinin tekrar adenini gÃ¶sterir. Bu sayede harhangi bir korpus sayÄ±sal olarak gÃ¶sterilmiÅŸ olur. Bir Ã¶rnek:

# 02.02.2020 free

EN YÃœKSEK DERECE MERKEZÄ°LÄ°ÄÄ° EN BÃœYÃœK Ã–NEM MÄ°DÄ°R

Bir aÄŸdaki herhangi bir dÃ¼ÄŸÃ¼me $n_i$  ait baÄŸlantÄ± sayÄ±sÄ± o dÃ¼ÄŸÃ¼me ait derece merkeziliÄŸini $d(n_k) $ ifade etmektedir. Derece merkeziliÄŸinin daÄŸÄ±lÄ±mÄ±, doÄŸal aÄŸlar iÃ§in, genellikle istatistiksel olarak *uzun kuyruk* olarak tanÄ±mlanan, yani belirli az sayÄ±da bulunan dÃ¼ÄŸÃ¼mlerin derece merkezilik deÄŸerlerinin Ã§ok fazla, geri kalanlarÄ±n derece merkezilik deÄŸerlerinin Ã§ok az olduÄŸu bir yapÄ±dadÄ±r. DoÄŸal olmayan bir aÄŸ (bilgisayar tarafÄ±ndan oluÅŸturulmuÅŸ) iÃ§in derece merkeziliÄŸi daÄŸÄ±lÄ±mÄ± uzun kuyruk yapÄ±sÄ±nda deÄŸildir. Derece merkeziliÄŸi genellikle bir dÃ¼ÄŸÃ¼mÃ¼n Ã§eÅŸitli bakÄ±mdan Ã¶nemini ifade etmek iÃ§in kullanÄ±lmaktadÄ±r. Ã–rneÄŸin bir sosyal iliÅŸki aÄŸÄ±nda en yÃ¼ksek derece merkeziliÄŸine sahip kiÅŸi bÃ¼yÃ¼k ihtimalle en Ã¶nemli kiÅŸidir. Ancak bu derece merkeziliÄŸinin sayÄ±sal olarak yanÄ±ltÄ±cÄ± olduÄŸu durumlar da sÃ¶z konusudur. Ã–rneÄŸin bir iÅŸ yerinde e-posta alma ve gÃ¶nderme iliÅŸkileri aÄŸ diyagramÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ÄŸÃ¼nde en bÃ¼yÃ¼k derece merkeziliÄŸi o ÅŸirketin yÃ¶neticilerine ait olacaktÄ±r. Ancak Ã¶te yandan sosyal ve mali iÅŸler gibi bir birimdeki yÃ¶netici de derece merkeziliÄŸine dayalÄ± Ã¶nem bakÄ±mÄ±ndan ÅŸirketin Ã¼retim departmanÄ±ndan daha Ã¶nemli olarak gÃ¶rÃ¼lebilir.  

AHP  + Ã‡OKLU AÄ ANALÄ°ZÄ°

Bunu yanÄ±lgÄ±ya dÃ¼ÅŸmemek iÃ§in alÄ±nabilecek Ã¶nlemlerden biri Ã¶nem analizinde bir dÃ¼ÄŸÃ¼me ait sadece tek bir aÄŸ deÄŸil farklÄ± aÄŸlar (Ã¶rneÄŸin aynÄ± iÅŸ yerindeki telefon aramalarÄ± aÄŸÄ±) gibi bir aÄŸ iÃ§in de derece merkezilik deÄŸerleri hesaplanarak bu deÄŸerlerin normal veya Ã¶zel olarak belirlenmiÅŸ aÄŸÄ±rlÄ±klÄ± ortalamasÄ± alÄ±nabilir. Peki hangi aÄŸÄ±n ne kadar Ã¶nemli olduÄŸu nasÄ±l belirlenebilir? Ä°ÅŸte bunun iÃ§in ise elde bulunan aÄŸlardaki derece merkezililk deÄŸerleri AHP ile bulunan Ã¶nem deÄŸerleri ile aÄŸÄ±rlÄ±klandÄ±rÄ±larak ortalamasÄ± alÄ±ndÄ±ktan sonra elde edilen deÄŸerler Ã¶nem derecesi olarak ele alÄ±nacaktÄ±r.

Matematiksel olarak ifade edilecek olursa, $N_i$ aÄŸÄ± iÃ§in bir dÃ¼ÄŸÃ¼mÃ¼n $n_k$ derece merkeziliÄŸi $d_i$, $N_j$ aÄŸÄ± iÃ§in bir dÃ¼ÄŸÃ¼mÃ¼n derece merkeziliÄŸi $d_j$ olmak Ã¼zere, mevcut aÄŸlar $N=(1,2,3...n)$ AHP analizinde $N_i$ aÄŸÄ± iÃ§in Ã¶nem derecesi $w_i$ olsun.  Bu durumda $n_k$ dÃ¼ÄŸÃ¼me ait Ã¶nem $\theta_k$: 
$$
\theta_k = \Sigma_i d_i.w_i
$$
olarak gÃ¶sterilebilir. 

Bunun yerine derece merkezilikleri ile ilgili birimin herhangi baÅŸka bir Ã¶zelliÄŸi kullanÄ±larak makine Ã¶ÄŸrenmesi de yapÄ±labilir.


# 01.02.2020 paper-tmnovdet

GÃ¶zetimsiz algoritmalarÄ±n gÃ¶zetimli algoritmalara Ã¼stÃ¼nlÃ¼ÄŸÃ¼ eÄŸitim verisine ihtiyaÃ§ duymamasÄ±dÄ±r. Bu durum analizlerin elde  eÄŸitim verisinin bulunmadÄ±ÄŸÄ± durumlarda faydalÄ± olacaktÄ±r. Ã–te yandan kÃ¼meleme algoritmasÄ±nÄ±n olasÄ± tÃ¼m kÃ¼meleri kendi buluyor olmasÄ± da veri seti iÃ§erisinde araÅŸtÄ±rmacÄ± tarafÄ±ndan gÃ¶rÃ¼lemeyecek kÃ¼melerin tespitine ya da mevcut kÃ¼melerden daha da kÃ¼Ã§Ã¼k ve homojen alt kÃ¼melerin ortaya Ã§Ä±karÄ±lmasÄ±na yardÄ±mcÄ± olabilir.   

# 31.01.2020 paper-tmnovdet

K-Means algoritmasÄ± herhangi bir veri seti iÃ§erisinde sÄ±nÄ±flandÄ±rma yaparken algoritma iÃ§in lazÄ±m olan tek bilgi kaÃ§ adet kÃ¼me belirleneceÄŸi (k) bilgisidir. Girilen bu deÄŸer ne olursa olsun algoritma ilgili sÄ±nÄ±flarÄ± bulacaktÄ±r. Ancak bu algoritma iÃ§in ideal *k* deÄŸerinin belirlenebilmesi iÃ§in *inertia* Ã¶lÃ§Ã¼tÃ¼nÃ¼n minimum olmasÄ± gerekir. Bu deÄŸer kÃ¼menin aÄŸÄ±rlÄ±k merkezinin kÃ¼menin elemanlarÄ±na uzaklÄ±klarÄ±nÄ±n toplamÄ±dÄ±r. KÃ¼melerin her biri iÃ§in hesaplanan bu deÄŸerlerin genel toplamÄ± ne kadar kÃ¼Ã§Ã¼k olursa, kÃ¼melerin birbirinden uzaklÄ±klarÄ± o kadar bÃ¼yÃ¼k olacaktÄ±r. 

TODO: K-means algoritmasÄ±nÄ±n Ã§alÄ±ÅŸma ÅŸekli

Åekilde gÃ¶rÃ¼len yaÅŸ ve gelir dÃ¼zeyi ile ilgili grafikte kÃ¼meler aÃ§Ä±kÃ§a gÃ¶rÃ¼lebilmektedir. Ä°ki parametreden oluÅŸan bÃ¶yle bir grafikte kÃ¼meleri herhangi bir algoritma kullanmadan da belirlemek mÃ¼mkÃ¼ndÃ¼r. Ancak parametr sayÄ±sÄ± arttÄ±ÄŸÄ±nda bunun grafiksel olarak gÃ¶rÃ¼mesi olanaklÄ± deÄŸildir. AynÄ± ÅŸekilde bazÄ± durumlarda kÃ¼meler grafikte kolayca fark edilmeyecek bir durumda da olabilir. 



# 30.01.2020 paper-tmnovdet

Metin madenciliÄŸinde kullanÄ±lan **gÃ¶zetimsiz** algoritmalardna biri de K-means adlÄ± algoritmadÄ±r. Bu algoritmanÄ±n Python Sklearn kÃ¼tÃ¼phanesi ile yazÄ±lmÄ±ÅŸ versiyonunda girilen k parametresi kadar kategori bu algoritma tarafÄ±ndan otomatik olarak belirlenir metin setindeki her bir kelime ile eÅŸleÅŸtirilir. 

TODO: Ã–rnek

TODO: Ã‡alÄ±ÅŸma ÅŸekli

# 29.01.2020 paper-tmnovdet

Metin seti iÃ§indeki bir kavramÄ±n yeni bir kavram olup olmadÄ±ÄŸÄ±nÄ± tespit edebilmek iÃ§in Ã¶ncelikle bu metin setinde gÃ¶rÃ¼len tÃ¼m kategorilerin sÄ±nÄ±flandÄ±rÄ±larak bu sÄ±nÄ±flandÄ±rmalarÄ±n hiÃ§ birine uymayan bir metnin ya da kavramÄ±n "yeni" olarak nitelendirilmesi mÃ¼mkÃ¼ndÃ¼r. BÃ¶yle bir yol izlenecekse Ã¶ncelikle metin madenciliÄŸinde kullanÄ±lan "sÄ±nÄ±flandÄ±rma (classifying)" ve "kÃ¼meleme (clustering)" yÃ¶ntemlerinin tanÄ±mlarÄ± ve aralarÄ±ndaki fark ele alÄ±nmalÄ±dÄ±r. Elde bulunan bir metin setinde bu metinde bulunan kategoriler (sÄ±nÄ±flar) **Ã¶nceden biliniyor** ve bu bir tahmin edici makine Ã¶ÄŸrenme algoritmasÄ±nÄ±n sadece bu kategorileri metinlerle eÅŸleÅŸtirmesi isteniyorsa bu yÃ¶ntem **sÄ±nÄ±flandÄ±rma** olarak kabul edilmektedir. YaygÄ±n kullanÄ±lan makine Ã¶ÄŸrenme algoritmalarÄ±ndan NaiveBayes, SVM, Decision Tree ve Random Forest gibi algoritmalarÄ±n yanÄ±nda derin Ã¶ÄŸrenme algoritmalarÄ± da bu tahminleri yapabilir. SÄ±nÄ±flandÄ±rmaya Ã¶rnek olarak ÅŸu Ã¶rnek vaka verilebilir:

*Ã–rnek Vaka 1: Bir haber sitesinde Ã¶nceden veri tabanÄ±nda bulunan bir milyon adet haber bulunmaktadÄ±r. Bu haberlerin sadece yirmi bin adedi "ekonomi","saÄŸlÄ±k" ve "politika" olmak Ã¼zere Ã¼Ã§ kategoriye sahiptir bu kategoriler haberlerin yer aldÄ±ÄŸÄ± sÃ¼tunun hemen yanÄ±ndaki sÃ¼tunda yer almaktadÄ±r. Geri kalan haberlerin de sadece bu Ã¼Ã§ kategori iÃ§erisinde yer aldÄ±ÄŸÄ± bilinmektedir. Bu durumda **sÄ±nÄ±flandÄ±rma** algoritmalarÄ± ile yirmi bin adet haber makineye Ã¶ÄŸretilir ve eÄŸer tatmin edici bir tahmin gÃ¼cÃ¼ elde edilirse (yine yirmi binlik veri seti Ã¼zerinde test edilerek) geri kalan haberlerin tamamÄ± otomatik olarak etiketlenir.*

NaiveBayes, SVM, Decision Tree ve Random Forest gibi makine Ã¶ÄŸrenme algoritmalarÄ±nÄ±n temel ortak noktasÄ± sadece sÄ±nÄ±flandÄ±rma yapmak deÄŸildir. Bu algoritmalar deÄŸer tahmini de yapabilirler. Ancak esas ortak Ã¶zellik, bu algoritmalarÄ±n **Ã¶ÄŸrenmek iÃ§in Ã¶rnek vakada ele alÄ±nan yirmi binlik Ã¶ÄŸrenme verisi** gibi veriye muhtaÃ§ olmalarÄ±dÄ±r. BaÅŸka bir deyimle bu algoritmalar hariÃ§ten bir Ã¶ÄŸrenme verisi olmadan herhangi bir tahmin gÃ¼cÃ¼ne sahip deÄŸildir. Bu nedenle bu algoritmalar **gÃ¶zetlemeli (supervized)** algoritmalar olarak tanÄ±mlanÄ±rlar.  Ã–rnek vaka 1'de algoritma yirmi binlik veri setinden etiketleri **Ã¶ÄŸrenmiÅŸtir**.

DiÄŸer yandan bazÄ± algoritmalar dÄ±ÅŸarÄ±dan Ã¶ÄŸrenme verisine ihtiyaÃ§ duymadan veri seti iÃ§erisindeki yapÄ±lara bakarak bzÄ± Ã§Ä±karÄ±mlar yapabilirler. Bu algoritmalar ise **gÃ¶zetimsiz (unsupervized)** algoritmalar olarak tanÄ±mlanÄ±rlar. Bu algoritmalara Ã¶rnek vaka 1'deki yirmi binlik Ã¶ÄŸrenme verisi vermeye gerek yoktur. Algoritma direkt olarak bir milyonluk ana veri seti iÃ§erisindeki olasÄ± kategorileri Ã§Ä±karabilirler. Ä°ÅŸte bu durumda Ã¶nceden herhangi "ekonomi", "saÄŸlÄ±k" ve "politika" gibi etiketler dÄ±ÅŸÄ±nda gÃ¶zden kaÃ§an "magazin" gibi bir etikete tekabÃ¼l edecek yapÄ±larÄ±n tespiti de mÃ¼mkÃ¼ndÃ¼r. Bu gÃ¶zetimsiz algoritmalar etiketlerin adlarÄ±nÄ± vermez, bunun yerine veri setindeki Ã¶nceden belirlenen Ã¶rneÄŸin *k* sayÄ±sÄ± kadar sÄ±nÄ±fÄ± bulup bunlara bir sayÄ± deÄŸeri atar, daha sonra bunlara tekabÃ¼l eden terimleri eÅŸleÅŸtirir. Bu sayÄ± deÄŸerleri altÄ±ndaki kavramlar incelendiÄŸinde bu kavramlarÄ±n genellikle insanlar tarafÄ±ndan adlandÄ±rÄ±lmÄ±ÅŸ "ekonomi", "saÄŸlÄ±k" veya "politika" gibi kategorilerle eÅŸleÅŸtiÄŸi gÃ¶rÃ¼lÃ¼r. Bu ikinci durumda **Ã¶nceden belirlenmiÅŸ** bir kategori seti bulunmamaktadÄ±r. Bu nedenle bu iÅŸlem bir **sÄ±nÄ±flandÄ±rma** deÄŸil **kÃ¼meleme** iÅŸlemi olmaktadÄ±r. KÃ¼meleme ile sÄ±nÄ±flandÄ±rmanÄ±n temel farkÄ± ÅŸudur: KÃ¼meleme yaparken tahmin edilecek kategorilerin listesinin Ã¶nceden belirlenmesine gerek yoktur.

YarÄ±n: K-means ile metin kategorizasyonunu anlat

# 28.01.2020 paper-tmnovdet

Metin madenciliÄŸi ile ilgili teknikler genellikle kelimelerin sÄ±klÄ±ÄŸÄ±na dayalÄ±dÄ±r. En basit ÅŸekliyle Ã§ok sayÄ±da dokÃ¼manÄ±n iÃ§erisinde en sÄ±k/yaygÄ±n kelimeleri Ã§Ä±karmak da bir metin madenciliÄŸi yÃ¶ntemidir. Kelime sÄ±klÄ±ÄŸÄ±na dayalÄ± analizler sÄ±k gÃ¶rÃ¼len kelimelerden doÄŸasÄ± gereÄŸi sÄ±k gÃ¶rÃ¼len kelimelerin (baÄŸlaÃ§lar gibi) ayÄ±klanmasÄ±nÄ± gerektirir. Bu ayÄ±klamadan sonra sÄ±k  gÃ¶rÃ¼len kelimeler tÃ¼m metinler hakkÄ±nda bir hÃ¼kÃ¼m verilebilmesine olanak verir.  Bu durum aslÄ±nda en Ã§ok "gÃ¶rÃ¼leni" ortaya Ã§Ä±karmaya yardÄ±m eder.  Bir metin seti makine yerine insan tarafÄ±ndan okunduÄŸunda varÄ±lacak hÃ¼kÃ¼mler yakÄ±ndÄ±r. DiÄŸer taraftan sadece bir veya daha fazla metin setinde gÃ¶rÃ¼len bir gÃ¼ndem, tema veya kavramÄ±n sÃ¶z konusu olduÄŸu durumda kelime sÄ±klÄ±k listesinin en Ã¼stÃ¼ndeki kelimeler deÄŸil, en altÄ±ndakiler Ã¶nemli hale gelir. Ancak bu "en az" gÃ¶rÃ¼len veya sadece bir kez gÃ¶rÃ¼len kelimelerin listesi de uzun olduÄŸunda hangi kavramÄ±n tesadÃ¼fen az gÃ¶rÃ¼len bir kavram olduÄŸu hangi kavramÄ±n da gerÃ§ekten yepyeni bir kavram olduÄŸunu Ã¶lÃ§menin bir yolu var mÄ±dÄ±r? Bu yepyeni kavramÄ±n gelecekte daha sÄ±k tartÄ±ÅŸÄ±lmaya baÅŸlanarak bu metin seti iÃ§erisinde yer alÄ±p almayacaÄŸÄ±nÄ± Ã¶lÃ§menin bir yolu var mÄ±dÄ±r? 


# 27.01.2020 - paper-localagenda-beingused

Bu Ã§alÄ±ÅŸma kapsamÄ±nda geliÅŸtirilen makine Ã¶ÄŸrenme algoritmasÄ± TÃ¼rkÃ§e haber siteleri ile ilgili olarak iki sorunun cevabÄ±nÄ±n bulunmasÄ±na yardÄ±mcÄ± oldu: Ä°lki, ulusal dÃ¼zeyde yayÄ±n yapan haber sitelerinde TÃ¼rkiye'deki herhangi bir il adÄ± aratÄ±ldÄ±ÄŸÄ±nda yerel olmasÄ± beklenen haberlerin ne kadarÄ±nÄ±n gerÃ§ekten yerel haber olduÄŸunun anlaÅŸÄ±lmasÄ± idi. DiÄŸer soru ise, bu yerel haberlerin gerÃ§ekten en Ã§ok hangi konularÄ± ele aldÄ±ÄŸÄ±ydÄ±. 

Ä°lk sorunun cevabÄ±nÄ±n haber sitelerinin okuyucularÄ±n ilgisini haber sitelerinde tutmak amacÄ±yla aslÄ±nda yerel olmayan haberleri de gÃ¶sterdiÄŸi gerÃ§eÄŸidir. Haber sitelerinin yerel ve yerel olmayan haberleri bir arada gÃ¶stermek suretiyle okurun ilgisini sÃ¼rdÃ¼rmeyi amaÃ§lamasÄ± olasÄ±dÄ±r. Bu durum kasten olmayarak ilgili sitelerin arama motoru algoritmalarÄ± ile ilgili bir problemden kaynaklanÄ±yor da olabilir.   

Ä°kinci sorunun cevabÄ± ilk soruya gÃ¶re algoritma tarafÄ±ndan yerel olmadÄ±ÄŸÄ± kesine yakÄ±n doÄŸrulukta bilinen haberlerin elenmesinden sonra ortaya Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r. Bu yapÄ±lÄ±rken, haberlerin "ilgili olabilecekleri" bilinen olay, yazÄ±lÄ± kaynaÄŸa dayalÄ± olma ve Ã¶zgÃ¼n haber ÅŸeklinde Ã¼Ã§ tipe gÃ¶re etiketlemesi yine algoritma tarafÄ±ndan gerÃ§ekleÅŸtirilmiltir. Buna gÃ¶re haberlerin Ã§oÄŸunun olaya dayalÄ± haberler (hava durumu, trafik kazalarÄ± toplantÄ±lar vs) olduÄŸu, daha sonra de yazÄ±lÄ± kaynaklara dayalÄ± haberlerin (mahkeme kararlarÄ±, yazÄ±lÄ± aÃ§Ä±klamalar vs.) ikinci sÄ±rada yer aldÄ±ÄŸÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Ã–zgÃ¼n haberler ise en son sÄ±rada ve Ã§ok az sayÄ±daki haberlerde gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Haberlerin tamamÄ±nda hakim olan bu sÄ±ralama herhangi bir haber kaynaÄŸÄ± ya da herhangi bir ile ilgili haberlerde deÄŸiÅŸmemiÅŸtir.  

Haberlerin genellikle olaylarÄ± ele almasÄ±, bu olaylarÄ±n da neredeyse sadece hava durumu, trafik kazalarÄ±, mahkeme kararlarÄ±, gibi haberler ziyaretleri ÅŸeklindeki iÃ§eriklerden oluÅŸmasÄ± hususu bu Ã§alÄ±ÅŸmadaki en teme sonuÃ§lardan biridir. Haber sitelerinin Ã§oÄŸunun ajans haberlerinden beslenmesi ve haberlerde derinlemesine iÃ§erikten ziyade sÃ¼rekli ve gÃ¼ncel bir akÄ±ÅŸÄ±n saÄŸlanmaya Ã§alÄ±ÅŸÄ±lmasÄ± niyeti bu durumun nedeni olarak gÃ¶rÃ¼lmektedir. Haberlerde kullanÄ±lan kelime hazinesinin TODO olmasÄ± ve bunun da Ã¶zellikle daha az bir anahtar terim etrafÄ±nda dolaÅŸmasÄ± bunun diÄŸer bir gÃ¶stergesidir. Yerel haberler iÃ§erisinde gÃ¶rÃ¼len yerel olmayan haberler de bu niyeti doÄŸrulamaktadÄ±r.

Bu Ã§alÄ±ÅŸmada geliÅŸtirilen Ã¶zel makine Ã¶ÄŸrenme algoritmasÄ± haber sitelerinin iÃ§eriklerinin sÄ±nÄ±flandÄ±rÄ±lmasÄ±nda  yerel - yerel olmama durumunu %TODO doÄŸrulukta tespit etmektedir. Bu algoritma veya benzerlerininin bu gÃ¼Ã§te tespit kapasitesi haberler Ã¼zerine araÅŸtÄ±rmalar yapan araÅŸtÄ±rmacÄ±larÄ± iÃ§in Ã¶zel bir araÃ§ olarak kullanÄ±labilir.  DiÄŸer taraftan haberlerin ele aldÄ±klarÄ± konularÄ± incelerken metin madenciliÄŸinin kullanÄ±lmasÄ± da haber analitiÄŸi iÃ§in baÅŸka bir kullanÄ±ÅŸlÄ± araÃ§ olarak ortaya Ã§Ä±kmaktadÄ±r.

Ã‡alÄ±ÅŸmanÄ±n sonuÃ§larÄ±nÄ±n baÅŸka araÅŸtÄ±rmalarla doÄŸrulanmasÄ± da olasÄ±dÄ±r. DiÄŸer yandan bu Ã§alÄ±ÅŸmada kullanÄ±lan mÃ¼hendislik-yoÄŸun  metot ve yaklaÅŸÄ±mlarÄ±n medya Ã¼zerine gerÃ§ekleÅŸtirilecek yeni Ã§alÄ±ÅŸmalarda Ã¶zellikle sosyal bilimler alanÄ±nda farklÄ± ve yeni araÅŸtÄ±rmalara yardÄ±mcÄ± olacaÄŸÄ± dÃ¼ÅŸÃ¼nÃ¼lmektedir. Sosyal bilimlerin fen bilimleri alanÄ±nda gÃ¶rece daha yaygÄ±n olan araÃ§lardan beslenmesi dÃ¼nyada da gittikÃ§e yaygÄ±nlaÅŸan bir olgudur.

# 26.01.2020 - paper-localagenda-beingused

HazÄ±rlanan sÄ±nÄ±flandÄ±rma algoritmasÄ± yerel ve yerel olmayan haberleri % TODO doÄŸrulukta tespit etmiÅŸtir. Bu algoritma ile yerel haberler olarak derlenen veri seti 1'deki tÃ¼m tÃ¼m haberlerin yerel olup olmadÄ±ÄŸÄ± tahmin edilerek, yerel haber olmadÄ±ÄŸu halde yerel haberler arasÄ±nda gÃ¶rÃ¼len haberlerin oranÄ± tespit edilmiÅŸtir.

Ä°stistansÄ±z olarak tÃ¼m haber sitelerinin arama sayfalarÄ±nda il adlarÄ± yazÄ±ldÄ±ÄŸÄ±nda o il ile hiÃ§ ilgisi olmayan haberlerin de geldiÄŸi gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Buna gÃ¶re kayank olarak kullanÄ±lan haber sitelerinden hangisinin sonuÃ§ sayfalarÄ±nda yazÄ±lan arama terimine "sadakati" % olarak ÅEKÄ°L todo'da gÃ¶sterilmiÅŸtir.

NOT: Yerel olmayan haberler elendikten sonra haberlerin konularÄ± hakkÄ±ndaki analizi yapmak daha isabetli olabilir. Bu nedenle Ã¶nce yukarÄ±daki paragrafÄ±n ele aldÄ±ÄŸÄ± kÄ±sÄ±mlar sÄ±raya konmalÄ± daha sonra da yerel gÃ¼ndemler.

YarÄ±n: SonuÃ§ Ã¼ret, sonucu dÃ¼ÅŸÃ¼n

# 24.01.2020 - paper-localagenda-beingused

**BaÅŸlÄ±k: AlgoritmalarÄ±n DorÄŸuluklarÄ±nÄ±n Ã–lÃ§Ã¼mÃ¼**

Bir sÄ±nÄ±flandÄ±rma algoritmasÄ±nÄ±n tahmin gÃ¼cÃ¼nÃ¼n **doÄŸruluÄŸu** (accuracy) tahmin ettiÄŸi sÄ±nÄ±flarÄ±n yÃ¼zde kaÃ§Ä±nÄ±n gerÃ§ekten o sÄ±nÄ±fta olduÄŸunun gÃ¶stergesidir. Algoritma'nÄ±n %98 doÄŸrulukta olmasÄ± algoritmanÄ±n 100 gÃ¶zlemin sÄ±nÄ±fÄ±nÄ±n 98'ini doÄŸru tahmin ettiÄŸi, 2'sini ise yanlÄ±ÅŸ tahmin ettiÄŸi anlamÄ±na gelir.

|Algoritma/GerÃ§ek| Negatif | Pozitif|
|---------|-----------|-------|
|Negatif| TN |FP|
|Pozitif| FN | TP |

*TODO: Tabloyu ÅŸÃ¶yle yap: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9*

Yorumlarken: https://medium.com/data-science-tr/s%C4%B1n%C4%B1fland%C4%B1rma-modellerinde-ba%C5%9Far%C4%B1-kriterleri-2d86488799c6

https://stanford.edu/~shervine/l/tr/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks

Bu Ã¶lÃ§Ã¼tler bir algoritmanÄ±n doÄŸruluÄŸunu deÄŸerlendirirken algoritmayÄ± farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ±na gÃ¶re ele almayÄ± saÄŸlamaktadÄ±r. Bununla ilgili ÅŸu Ã¶rnek verilebilir: Bir kiÅŸinin en ufak bir ihtimal de olsa kanser teÅŸhisini yakalamak isterken TODO skorunu kullanÄ±rÄ±z. Bu skor yÃ¼kseldikÃ§e genellikle kanser olmayan kiÅŸilerin de kanserli  olarak deÄŸerlendirilme olasÄ±lÄ±ÄŸÄ± vardÄ±r. Ancak bu durumdan geri dÃ¶nÃ¼lebilir. Ã–te yandan bir kiÅŸinin suÃ§lu olup olmadÄ±ÄŸÄ±nÄ± tespit ederken bu eÅŸik yerine TODO kullanÄ±labilir. Nitekim suÃ§suz birinin suÃ§lu muamele gÃ¶rmesi ihtimalindense az da olsa suÃ§lu bir kaÃ§ kiÅŸinin masum deÄŸerlendirilmesine razÄ± gelinmiÅŸ olmaktadÄ±r.

Bu algoritmalar incelenirken onlarÄ±n kusursuz Ã§alÄ±ÅŸmalarÄ± beklenebilir. Ancak genellikle bu durum imkansÄ±za yakÄ±ndÄ±r. %100 doÄŸrulukta tahmin yapabilen  bir algoritmanÄ±n tahmin ettiÄŸi alan ya gerÃ§ekten Ã§ok basittir ya da algoritmanÄ±n "ezberleme" olarak da nitelendirilen "overfit" durumu sÃ¶z konusudur.  KaldÄ± ki algoritmalarÄ±n doÄŸruluÄŸu iÃ§in kullanÄ±lan test verisine gÃ¶re bu deÄŸerler elde edilmektedir. Bir algoritma ise sonsuza kadar test edilemez. Bu nedenle mutlak kusursuzluk sÃ¶z konusu deÄŸildir. 

Bir sÄ±nÄ±flandÄ±rÄ±cÄ± makine Ã¶ÄŸrenme algoritmasÄ±nÄ±n en az %50'i Ã¼zerinde doÄŸru tahmin yapmasÄ± beklenir nitekim iki ihtimalin sÃ¶z konusu olduÄŸu durumda gerÃ§ek tahmin yerine yazÄ± tura atÄ±larak tahmin halinde bile %50 doÄŸruluk saÄŸlanacaktÄ±r. 



# 23.01.2020 - paper-localagenda-beingused

*NOT: DÃ¼n bir haberin yerel olup olmadÄ±ÄŸÄ±nÄ± Ã¶lÃ§Ã¼p Ã¶lÃ§emeyeceÄŸimi dÃ¼ÅŸÃ¼nÃ¼rken, bunun imkansÄ±z olduÄŸuna karar vermiÅŸtim. Ancak ulusal gÃ¼ndemleri makineye Ã¶ÄŸreterek bunun mÃ¼mkÃ¼n olabileceÄŸine karar verdim.Åimdi o minvalde yazacaÄŸÄ±m* 

Haberlerin iÃ§erisinde yer alan ve yerel olmadÄ±ÄŸÄ± halde kaynak haber sitelerinin arama sonuÃ§larÄ±nda yerel haber olarak listelenen haberleri ayÄ±klamak iÃ§in de makine Ã¶ÄŸrenmesi kullanÄ±lmÄ±ÅŸtÄ±r. Bunun iÃ§in TODO kelime listesesinde yer alan ve sonuÃ§larÄ±nÄ±n sadece **ulusal** haberler olduÄŸu bilinen TODO adet haber ulusal olarak, TODO kadar haber de yerel haberlerden seÃ§ilerek bu veri (Bundan bÃ¶le veri seti 2 olarak tanÄ±mlanmÄ±ÅŸtÄ±r) makineye Ã¶ÄŸretilmiÅŸtir.  Bayes algoritmasÄ± ile eÄŸitilen algoritmanÄ±n doÄŸruluÄŸu % TODO kadardÄ±r. AlgoritmanÄ±n doÄŸruluÄŸu ile ilgili diÄŸer Ã¶lÃ§Ã¼tler ÅŸekil TODO'da gÃ¶sterilmektedir. Bu algoritma ile daha Ã¶nce derlenen veri seti 1 iÃ§erisindeki haberlerden yerel olanlarla ulusal olan haberler ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Buna gÃ¶re haberlerin % TODO'su yerel olmadÄ±ÄŸÄ± halde kaynak haber siteleri iÃ§erisnde yerel haberler arasÄ±nda listelenmiÅŸtir. Hangi haber sitesinde yerel olmadÄ±ÄŸÄ± halde yerel gÃ¶zÃ¼ken ne kadar olduÄŸu gÃ¶sterilmektedir. Bu deÄŸerlerin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ilgili haber sitelerinin arama sonuÃ§larÄ±ndaki zayÄ±flÄ±ÄŸÄ± da temsil etmektedir. 

Veri Setleri
|No|AdÄ±|SatÄ±r SayÄ±sÄ±|AmaÃ§|
|--|-----------|-----|----------|
|1|Ä°l adlarÄ± ile ilgili elde edilen yerel haberler|TODO|AraÅŸtÄ±rma veri seti|
|2|Ulusal gÃ¼ndemlerle ilgili elde edilen haberler|TODO|Yerellik-UlusallÄ±k ayrÄ±ÅŸtÄ±rma algoritmasÄ± eÄŸitim verisi|

*TODO:FIND A PLACE IN TEXT*
*Makine Ã¶ÄŸrenme algoritmasÄ± ile ilgili  bir bÃ¶lÃ¼m aÃ§*
Makina Ã¶ÄŸrenmesi bilgisayarlarÄ±n aÃ§Ä±kÃ§a programlanmaksÄ±zÄ±n bilinmeyen deÄŸerleri sÄ±nÄ±flandÄ±rma  tahmin edebilmesini saÄŸlayan algoritmalardÄ±r. Bunu yaparken sadece elde bulunan mevcut verilerden yola Ã§Ä±karak hareket ederler. Bu algoritmalarÄ±n tahmin kabiliyeti teorik olarak Ä±spatlanmÄ±ÅŸtÄ±r. AynÄ± ÅŸekilde elde bulunan verilerin bir kÄ±smÄ± ayrÄ±larak bu elde bulunan verilerle eÄŸitilen algoritmalarÄ±n ne kadar doÄŸru tahmin edildiÄŸi 3 temel Ã¶lÃ§Ã¼tle deÄŸerlendirilmektedir. Bu Ã¶lÃ§Ã¼ter yazÄ±nda genel kabul edilmiÅŸ Ã¶lÃ§Ã¼tlerdir.

YarÄ±n: DoÄŸruluk ve kesinliÄŸi ve F1 skorunu metin iÃ§i anlat, bunu anlatÄ±rken PN, TN mevzularÄ±nÄ± da anlat.


# 22.01.2020 - paper-localagenda-beingused

Derlenen yerel haberler incelendiÄŸinde (TODO: Sample tÃ¼m kolonlar) haberlerin ilgili olduklarÄ± illerle (kolon TODO) uyumlu olduÄŸu gÃ¶rÃ¼lÃ¼rken diÄŸer bir kÄ±smÄ±nÄ±n ise ilgili olmadÄ±ÄŸÄ± gÃ¶rÃ¼lmektedir. Bunun nedeni ÅŸudur: Haber sitesine girerek sÃ¶z gelimi "Van" anahtar terimi ile ilgili arama yapÄ±ldÄ±ÄŸÄ±nda Ã§Ä±kan haberlerin ilk kÄ±sÄ±mlarÄ± genellikle anahtar terimle ilgili iken sonraki haberler anahtar terimle ilgisiz durumdadÄ±r. Bu durum bir Ã§ok TÃ¼rkÃ§e haber sitesinin ortak problemidir (TODO: Teyit et). Bu makale kapsamÄ±nda geliÅŸtirilen algoritmalardan haber toplayÄ±cÄ± algoritma (Bundan bÃ¶yle: Algoritma-T olarak adlandÄ±rÄ±lacaktÄ±r) ilgili haber sitelerine girdiÄŸinde aynÄ± haberleri elde etmektedir. Burada bir yazÄ±lan bir anahtar terim ile ortaya Ã§Ä±kan haberlerden herhangi birinin ilgililiÄŸini Ã¶lÃ§ecek basit bir yaklaÅŸÄ±m bulunmamaktadÄ±r. AÅŸaÄŸÄ±daki haberleri ele alalÄ±m. AÅŸaÄŸÄ±daki haberlerin "Van" anatar terimi yazÄ±ldÄ±ÄŸÄ±nda bir haber sitesinde arama sonuÃ§larÄ±nda listelenen haberler olduÄŸunu kabul edelim:

1- BakanlÄ±k aÃ§Ä±kladÄ±: Sistem sil baÅŸtan!

2- Adadaki tarihi yapÄ±lar koruma altÄ±na alÄ±nacak

3- GÃ¼rpÄ±nar'da 23 Nisan kutlamalarÄ±

4- Van'Ä±n sesi olacaÄŸÄ±z

YukarÄ±daki haberler incelendiÄŸinde 4. haber'de birebir "Van" ifadesini iÃ§ermesi nedeniyle "Van" ile ilgili olduÄŸu kolayca sÃ¶ylenebilir. 3. haber de Van ile ilgili olmakla birlikte bununun anlaÅŸÄ±labilmesi iÃ§in "GÃ¼rpÄ±nar" ilÃ§esinin Van'da olduÄŸu bilgisi gereklidir. 2. haberin Van'la ilgili olma olasÄ±lÄ±ÄŸÄ± vardÄ±r (Van gÃ¶lÃ¼nde bulunan bir adadan Ã¶tÃ¼rÃ¼) ancak bu yanlÄ±ÅŸklÄ±kla arama sonuÃ§larÄ±na dahil olanbaÅŸka bir yere ait bir haber de olabilir. Birinci haber ise yerel olmayan bir haberdir.

"Ä°lgililiÄŸi" Ã¶lÃ§mek iÃ§in akla haber metni iÃ§inde anahtar terim (ilin adÄ±) ve ilgili anahtar terimler (ilÃ§eler) yazmak gelebilir. Bu durum bir derece Ã¶lÃ§me gÃ¼cÃ¼ saÄŸlayama potansiyeli barÄ±ndÄ±rÄ±r. Ancak bir ildeki ilÃ§eler dÄ±ÅŸÄ±ndaki kÃ¶y ve mahalleler gibi tÃ¼m yer adlarÄ± hatta tarihi eser yahut cadde veya sokak adlarÄ± da haber baÅŸlÄ±ÄŸÄ±nda bir gÃ¶sterge terim olabilir. Bu ÅŸekilde bir karÅŸÄ±laÅŸtÄ±rma listesi Ã§Ä±karmak ayrÄ± bir inceleme konusudur. 

Arama sonuÃ§larÄ±ndaki bu zayÄ±flÄ±ÄŸÄ±n nedeni haber sitelerinin site iÃ§i arama algoritmalarÄ±nÄ±n zayÄ±flÄ±ÄŸÄ± olabilir. Ã–te yandan bu durum, okuyucuyu haber sitesinde tutmak iÃ§in kasten yapÄ±lmasÄ± da olasÄ±dÄ±r. Her halÃ¼karda bu durum ilgili haber sitesinin arama motorunun bir zayÄ±flÄ±ÄŸÄ± olarak deÄŸerlendirilmelidir.  Bu Ã§alÄ±ÅŸmada her bir haber sitesinin arama motorlarÄ±nda Ã§Ä±kan sonuÃ§larÄ±n anahtar terimle gÃ¶rece ilgili olduÄŸu varsayÄ±lmaktadÄ±r. (TODO: VarsayÄ±m listesine ekle).  Haber arama sonuÃ§larÄ±nda farklÄ± illerin sÃ¶z konusu olmasÄ± halinde dahi Ã§Ä±kan haberlerin tamamÄ± ayrÄ±ca incelenmekte olduÄŸundan bu durum araÅŸtÄ±rmanÄ±n saÄŸlÄ±ÄŸÄ±na zarar vermemektedir. Sadece illerle ilgili olarak yapÄ±lacak analizlerde sapma ihtimali sÃ¶z konusudur. 

*NOT: Burada baÅŸka bir makale konusu Ã§Ä±kmÄ±ÅŸ oluyor, bu Ã§alÄ±ÅŸmamda haberlerin yazÄ±m alÄ±ÅŸkanlÄ±klarÄ±nÄ± incelemekteyim bu nedenle yukarÄ±daki tanÄ±mlayÄ±cÄ± aÃ§Ä±klamalar dÄ±ÅŸÄ±nda ilgililik yakalama algoritmasÄ±nÄ±limdilik baÅŸka bir Ã§alÄ±ÅŸmaya bÄ±rakÄ±yorum. Ä°lgililik yakalama algoritmasÄ± Ã¶zel bir algoritma olarak haber sitelerinin arama algoritmalarÄ±nÄ± sadece yerel haberler deÄŸil genel olarak analiz edebilir. Bence buradan gÃ¼zel bir yabancÄ± dilde makale de Ã§Ä±kabilir.*



# 17.01.2020 - paper-localagenda-beingused

Politik veya iÅŸ dÃ¼nyasÄ± ile ilgili haberler dÄ±ÅŸÄ±ndaki haberlerin herhangi bir yanlÄ±ÅŸ yÃ¶nlendirme iÃ§ermesi daha az olasÄ±dÄ±r. Yerel haberlerin konu edildiÄŸi saha Ã¼lkenin geneline gÃ¶re daha dar ve izlenebilir olduÄŸundan buradaki haberlerin daha nesnel olacaÄŸÄ± tahmin edilebilir. Ancak bu nesnellik haberlerin Ã¶zgÃ¼n olmayan kliÅŸe "duyuru" biÃ§imine dÃ¶nÃ¼ÅŸme olasÄ±lÄ±ÄŸÄ±nÄ± arttÄ±ran bir faktÃ¶rdÃ¼r. Ã–zgÃ¼n olmayan ve genellikle her yÄ±l bir biÃ§imde tekrar eden tÃ¼m haberleri (toplantÄ±, aÃ§Ä±lÄ±ÅŸ, mahkeme, hava durumu, ziyaret vs.) monoton olarak sÄ±nÄ±flandÄ±rmak ve gerek il gerekse haber kaynaÄŸÄ± aÃ§Ä±sÄ±ndan deÄŸerlendirmek yerel gÃ¼ndemlerle ilgili basÄ±nÄ±n haber yazÄ±m alÄ±ÅŸkanlÄ±klarÄ±nÄ± ortaya Ã§Ä±karacaktÄ±r. Bu Ã§alÄ±ÅŸma bu amaca yÃ¶nelik olarak hazÄ±rlanmÄ±ÅŸtÄ±r. Bunu yaparken ilk akla gelen yÃ¶ntem haberlerin teker teker incelenerek monotonluk sÄ±nÄ±flandÄ±rmasÄ±nÄ±n buna gÃ¶re yapÄ±lmasÄ±dÄ±r. Bu miktardaki haber iÃ§in bu iÅŸlem imkansÄ±z deÄŸilse de Ã§ok zor olacaktÄ±r. DiÄŸer taraftan bu gerÃ§ekleÅŸtirilse bile yeni haberler sÃ¶z konusu olduÄŸunda aynÄ± okuma iÅŸleminin tekrar edilmesi gerekecektir. AyrÄ±ca haber sayÄ±sÄ±nÄ±n Ã§ok daha falza ve sÃ¼rekli olduÄŸu gÃ¼nÃ¼mÃ¼zde bu tÃ¼r araÅŸtÄ±rmalar iÃ§in insan dikkat ve zamanÄ±nÄ± kullanmak efektif olmaz. 

Bu amaca yÃ¶nelik bir araÅŸtÄ±rmada haber analizi iÃ§in diÄŸer bir yol daha vardÄ±r. O da **metin madenciliÄŸi** adÄ± verilen yÃ¶ntemdir. Metin madenciliÄŸi, Ã§ok miktardaki metin yÄ±ÄŸÄ±nlarÄ± iÃ§inden bilgi ayÄ±klama, Ã¶zetleme, mevcut bilgileri istenen ÅŸekilde sÄ±nÄ±flandÄ±rma gibi bir Ã§ok Ã¶zel iÅŸlevi insanlarÄ±n haberleri okumasÄ±na ihtiyaÃ§ bÄ±rakmadan saÄŸlayan yÃ¶ntemler bÃ¼tÃ¼nÃ¼dÃ¼r. Elde bulunan bir metin yÄ±ÄŸÄ±nÄ± Ã¼zerinden analiz yapmaya yarayacak bir takÄ±m hazÄ±r araÃ§lar mevcuttur. RapidMiner, Weka gibi yazÄ±lÄ±mlar metin madenciliÄŸi iÃ§in gÃ¶rsel kullanÄ±mÄ± olan daha kolay araÃ§lardÄ±r. Ã–te yandan metin madenciliÄŸinin de dahil olduÄŸu tÃ¼m veri madenciliÄŸi yÃ¶ntemlerini kullanabilmek iÃ§in gÃ¶rsel kullanÄ±mÄ± az olan ancak Ã§ok gÃ¼Ã§lÃ¼, hÄ±zlÄ± ve esnek araÃ§lar bulunmaktadÄ±r. Bu araÃ§lar birer *paket program* olmayÄ±p kullanÄ±sÄ±nÄ±n yazÄ±lÄ±m mÃ¼hendisliÄŸi ve cebir gibi alanlarda en az temel dÃ¼zeyde bilgisini gerektirirler. Bu araÃ§lar R, Python ve Julia gibi yazÄ±lÄ±m dilleridir. Bu Ã§alÄ±ÅŸmada R dili kullanÄ±larak sÃ¶zÃ¼ edilen yerel haberlerin monotonluk analizi gerÃ§ekleÅŸtirilmiÅŸtir.

Ã‡alÄ±ÅŸmanÄ±n izleyen ilk bÃ¶lÃ¼mÃ¼nde makalenin metin madenciliÄŸine dayalÄ± metodolojisi ele alÄ±nacak, sonraki  bÃ¶lÃ¼mÃ¼nde ise bu metotlarla gerÃ§ekleÅŸtirilen Ã§alÄ±ÅŸmanÄ±n sonuÃ§larÄ± ele alÄ±nacaktÄ±r. Son bÃ¶lÃ¼mde ise elde edilen bulgular tartÄ±ÅŸÄ±lacaktÄ±r. Bu Ã§alÄ±ÅŸmada kullanÄ±lan **Ã¶zgÃ¼nlÃ¼k Ã¶lÃ§eÄŸinin** (TODO: Ã–nceki monotonluk Ã¶lÃ§eÄŸi ifadesi yerine Ã¶zgÃ¼nlÃ¼k ifadesini kullan) gelecekte medya Ã¼zerine yapÄ±lan analizlerde monotonluÄŸu Ã¶lÃ§meye yarayacak bir kalite gÃ¶stergesi olarak kullanÄ±lmasÄ± amaÃ§lanmaktadÄ±r.

YÃ¶ntem

Bu Ã§alÄ±ÅŸma kapsamÄ±nda bir haberi Ã¶zgÃ¼nlÃ¼ÄŸÃ¼ algÄ±layacak sistemi tasarlamadan Ã¶nce bir haberin Ã¶zgÃ¼n olmadÄ±ÄŸÄ±na iÅŸaret eden Ã¶zelliklerin gÃ¶zden geÃ§irilmesinde fayda vardir. Bir haberde Ã¶zgÃ¼n olmama herhangi bir konunun *sÃ¼rekli tekrarÄ±* ya da daha Ã¶nce tekrar edilmese dahi [TODO'un](../00-reading_notes/haber_kaynaklari.md)  tanÄ±mÄ±na gÃ¶re haberi kaleme alan kiÅŸinin gÃ¶zleminden ziyade mevcut olay ve olgularla ilgili *kliÅŸe* aÃ§Ä±klamarla ilgili olmasÄ± anlamÄ±na gelir. Burada mevcut olay ve olgulara dayandÄ±ÄŸÄ± halde Ã¶zgÃ¼n yorum ve aÃ§Ä±klamalara dayalÄ± haberlerin Ã¶zgÃ¼n olmamasÄ±ndan sÃ¶z edilemez. Bu bakÄ±mdan herhangi bir Ã¶zgÃ¼nlÃ¼k sÄ±nÄ±flandÄ±rmasÄ±nda bu hususun da dikkate alÄ±nmasÄ± zorunlu olur. Bu iki nicel gÃ¶stergeyi nitel ve yansÄ±z olarak ele almak iÃ§in mevcut haberler ÅŸu iÅŸlemlerden geÃ§irilecektir.

1- Metin madenciliÄŸi ile tÃ¼m yerel haberlerde en sÄ±k tekrar eden kavramlar listelenecektir. Bu listedeki kavramlar daha sonra gruplandÄ±rÄ±lacaktÄ±r. Bu iÅŸlem sonunda elde bir haberin sÃ¼rekli tekrar eden gÃ¼ndemlerle ilgili olup olmamasÄ± ile ilgili anahtar terimler elde edilmiÅŸ olacaktÄ±r. Bu anahtar terimleri iÃ§eren haberler *tekrar eden haber* kategorisinde olacaktÄ±r. TÃ¼m haberler bu kategoriye gÃ¶re otomatik olarak kontrol edilerek iÅŸaretlenecektir.  Tekrar eden haber sÄ±nÄ±fÄ±nda olmayan haberler 1 puan alacaktÄ±r. Burada en sÄ±k tekrar eden kavramlar iÃ§in sÄ±klÄ±k eÅŸiÄŸi $f$ belirlemek gerekecektir. Bu deÄŸer arttÄ±kÃ§a daha fazla sayÄ±da haber Ã¶zgÃ¼n olmama kategorisine girebilir.  Makul sayÄ±da haberi belirleyebilmek iÃ§in $f$ deÄŸiÅŸkeninin az, orta ve yÃ¼ksek oranda  eÅŸiÄŸe gÃ¶re sÄ±nÄ±flandÄ±rma yapÄ±lacaktÄ±r.

2-  TODO'nun sÄ±nÄ±flandÄ±rmasÄ±na giren kavramlar ise bir Ã¶nceki listeden derlenerek yeni bir anahtar terim listesi oluÅŸturulacaktÄ±r. Bu liste ise *kliÅŸe* haberlere tekabÃ¼l edecektir. Bu kategoriye girmeyen haberler +1 puan daha alacaktÄ±r. Bu iÅŸlemler sonunda elde edilen Ã¼Ã§ tip haber olur:

 - 0: KliÅŸe haber
 - 1: YarÄ± Ã¶zgÃ¼n haber
 - 2: Ã–zgÃ¼n haber

3- YukarÄ±daki iÅŸlemlerle elde edilen Ã¶zgÃ¼nlÃ¼k oranlarÄ±nÄ± teyit etmek iÃ§in elle deÄŸerlendirilen haberlerle geliÅŸtirilen yapay zeka aracÄ± tÃ¼m haberleri yukarÄ±daki puanlamaya gÃ¶re makine Ã¶ÄŸrenmesi ile puanlayacaktÄ±r. Bu adÄ±mda yapay zekanÄ±n doÄŸruluk gÃ¼cÃ¼nÃ¼n yÃ¼ksek olmasÄ± durumunda Ã¶nceki adÄ±mlarda elde edilen *kelime bazlÄ± etiketleme* ile bu adÄ±mada elde edilen *yapay zeka bazlÄ± etiketleme* gÃ¼cÃ¼ mukayese edilecektir.

4- Haber Ã¶zgÃ¼nlÃ¼ÄŸÃ¼nÃ¼ belirleyen algoritma Ã¼retildikten sonra *haber kaynaÄŸÄ±* ve haberin ilgili olduÄŸu *il* bilgisine gÃ¶re hangi haber kaynaklarÄ± ve hangi illerde daha Ã¶zgÃ¼n haberlerin gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¶rnekleri ile birlikte incelenecektir.

5- Elde edilen Ã¶zgÃ¼nlÃ¼k tespit algoritmasÄ± daha sonra araÅŸtÄ±rmacÄ±larÄ±n kendi ellerindeki haber setlerinde benzer Ã§alÄ±ÅŸmalarÄ± yapabilecekleri halde bir yazÄ±lÄ±m olarak sunulacaktÄ±r.

# 15.01.2010 - paper-localagenda-beingused

Ã–te yandan zaman zaman medyada karÅŸÄ±laÅŸÄ±lan ve herhangi bir olguyu enine boyuna inceleyen ve gerÃ§ekten okur iÃ§in bilgilendirici olan haberlerle de karÅŸÄ±laÅŸÄ±lmaktadÄ±r. Bu tÃ¼r haberler okur iÃ§in ilgi Ã§ekiciliÄŸi sÃ¼rdÃ¼rmekle beraber okurun merakÄ±nÄ± istismar etmek yerine doyurmaktadÄ±r. Ã–rneÄŸin 2600 yÄ±ldÄ±r Ã§Ã¼rÃ¼meyen bir beyin dokusu ile ilgili bir haberde ÅŸu ifade geÃ§miÅŸtir: 

"YumuÅŸak dokularÄ±n korunmasÄ± iÃ§in genellikle kurutulmalarÄ±, dondurulmalarÄ± ya da oksijen iÃ§ermeyen asidik bir ortamda saklanmasÄ± gerekiyor. Ã‡Ã¼nkÃ¼ bir dÄ±ÅŸ etki bulunmasa bile hÃ¼crelerin doÄŸal enzimleri kendilerini yok etmeye baÅŸlÄ±yor. [Kaynak](https://www.independentturkish.com/node/115286/bilim/2-bin-600-y%C4%B1ll%C4%B1k-beyin-dokusu-bozulmam%C4%B1%C5%9F-halde-bulundu-peki-bu-nas%C4%B1l-m%C3%BCmk%C3%BCn)" 

Bu haberin ÅŸu ÅŸekilde de daha Ã§arpÄ±cÄ± ve dikkat Ã§ekici ÅŸeklide verilmesi mÃ¼mkÃ¼ndÃ¼r: 

"Mucizevi beynin 2600 yÄ±ldÄ±r nasÄ±l Ã§Ã¼rÃ¼mediÄŸi gizemini koruyor. Bir din adamÄ±na ait olduÄŸuna inanÄ±lan bu beyin..."

Ä°kinci formda, haberdeki "olduÄŸuna inanÄ±lan" ifadesinde Ã¶zne belirsizdir. Benzer ÅŸekilde TÃ¼rk basÄ±nÄ±nda sÄ±kÃ§a kullanÄ±lan "olarak yorumlandÄ±"  tabiri de aslÄ±nda sadece yazarÄ±n subjektif gÃ¶rÃ¼ÅŸÃ¼dÃ¼r ancak Ã¶zne gizlenerek bilerek veya bilmeyerek haberler Ã§arpÄ±tÄ±lmaktadÄ±r.  Bu Ã§arpÄ±tma sadece haberin ilgi Ã§ekiciliÄŸini arttÄ±rmaktan, toplumsal olaylarÄ± kÃ¶rÃ¼klemek amacÄ±na kadar farklÄ± niyetlerle gerÃ§ekleÅŸtirilebilir. Haberlerle ilgili bu Ã§arpÄ±tmalar Ã¼zerine araÅŸtÄ±rmalar yapan sivil toplum kuruluÅŸu olan First Draft adlÄ± kuruluÅŸa gÃ¶re bir haberin "yanlÄ±ÅŸ yÃ¶nlendirici" ya da "yanlÄ±ÅŸ bilgilendirici" formu yedi farklÄ± ÅŸekilde gerÃ§ekleÅŸebilir (Kaynak: First Draft, Clarire [https://twitter.com/erenbilal/status/1216804327500718086?s=21](https://twitter.com/erenbilal/status/1216804327500718086?s=21)). 

1- Parodi Haberler: Herhangi bir kiÅŸi veya kuruma yÃ¶nelik zarar niyeti yoktur. Ancak anlamsÄ±z veya gerÃ§ekÃ§i olmayan iÃ§erik sÃ¶z konusudur.

2-YanlÄ±ÅŸ yÃ¶nlendirici iÃ§erik: Bir haberde bir kiÅŸi veya kuruma yÃ¶nelik Ã¶zellikle Ã§arpÄ±tÄ±lan bir iÃ§erik vardÄ±r.

3-Sahtekar iÃ§erik: Orjinal kaynaklarÄ±n haberleri Ã§arpÄ±tÄ±larak verilmektedir.

4- ÃœretilmiÅŸ Ä°Ã§erik: Burada iÃ§erik tamamen sahtedir. Herhangi bir dayanaÄŸÄ± yoktur. Haberin tek amacÄ± zarar vermektedir.

5- HatalÄ± BaÄŸlantÄ±: Haberin gÃ¶rseli veya baÅŸlÄ±ÄŸÄ± ile iÃ§eriÄŸi arasÄ±nda iliÅŸki yoktur.

6- HatalÄ± BaÄŸlam: Haber orjinal ve doÄŸrudur ancak bu haber sosyal medya veya benzeri kanallardan yayÄ±lÄ±rken yanlÄ±ÅŸ bir baÄŸlamda yayÄ±lmaktadÄ±r.

7- ManipÃ¼le Ä°Ã§erik: Orjinal bir iÃ§eriÄŸin veya resminin kasten insanlarÄ± kandÄ±rmak iÃ§in ÅŸekillendirilmesidir.



Dipnot: "Olarak yorumlandÄ±" ÅŸeklinde Google Haberler iÃ§erisinde arama yapÄ±ldÄ±ÄŸÄ±nda 26.000 adet "gizli Ã¶zneli" TÃ¼rkÃ§e haber ortaya Ã§Ä±kmaktadÄ±r. Bu sayÄ± 2018 ila 2020 yÄ±llarÄ± arasÄ±ndadÄ±r.

# 13.01.2020 - paper-localagenda-beingused

Monotonluk vasfÄ±nÄ± ortaya Ã§Ä±karan en temel kaynak haberin konusudur. Haber konusu ise haberin kelimelerinden anlaÅŸÄ±labilir. TODO monotonluÄŸu nasÄ±l Ã¶lÃ§eceÄŸini yaz.

Monotonluk neden Ã¶lÃ§Ã¼lmelidir? Haberlerin sÃ¼rekli olarak benzer gÃ¼ndemlerin etrafÄ±nda veya iÃ§erisinde dolaÅŸÄ±yor olmasÄ± bir sÃ¼re sonra bu gÃ¼ndemlerin dÄ±ÅŸÄ±nda hiÃ§ bir konunun haberleÅŸememesine neden olabilir. Bu durum artÄ±k doÄŸal akÄ±ÅŸÄ± iÃ§erisinde geliÅŸecek olgularÄ±n habere dÃ¶nÃ¼ÅŸmesi yerine, haberleÅŸtirilecek olgularÄ±n yaratÄ±larak haberleÅŸirilmesine ve sÄ±ÄŸ dÃ¶ngÃ¼lere neden olur. Ã–zellikle ziyaret ve etkinlik haberlerinin haber sitelerinde sÃ¼rekli olarak yer bulmaktadÄ±r ancak Ã§oÄŸu kez bu etkinliklerin ne Ã¼rettiÄŸi ya da neyle sonuÃ§landÄ±ÄŸÄ± belirsizdir. Ã‡eÅŸitli ÅŸehirlerimizde gerÃ§ekleÅŸtirilen kariyer gÃ¼nleri toplantÄ±larÄ±, yerel tarihle ilgili gerÃ§ekleÅŸtirilen paneller ve benzeri haberler ya da herhangi bir bÃ¼rokratÄ±n bir hastayÄ± ziyareti tÃ¼rÃ¼nden haberlerin "Ã¶ncesi" ve "sonrasÄ±" belirsizdir. BaÅŸka bir deyimle neden gerÃ§ekleÅŸtirildiÄŸi ve daha uzun vadede ne ile sonuÃ§landÄ±ÄŸÄ± belli deÄŸildir.

# 12.01.2020 - paper-localangenda-beingused

"Kar alarmÄ±", "cezasÄ±na Ã§arptÄ±rÄ±ldÄ±" "start verildi", "toplantÄ±sÄ± gerÃ§ekleÅŸtirildi", "vurgulandÄ±", "karayolunda can pazarÄ±" gibi kalÄ±plar bir Ã§ok okur ya da dinleyici iÃ§in "haber" kavramÄ±nÄ± Ã§aÄŸrÄ±ÅŸtÄ±racaktÄ±r. Bu kavramlar sadece haber jargonu olarak haberlerin iÃ§erisinde ara sÄ±ra karÅŸÄ±laÅŸtÄ±mÄ±z kavramlar olarak gÃ¶zÃ¼kmektedir.  DiÄŸer taraftan, bu kavramlar bir haberin konusunu oluÅŸturabilecek ve aslÄ±nda oldukÃ§a sÄ±nÄ±rlÄ± bir dizi konu ile eÅŸleÅŸmektedir. Bu konular: olay, belge TODO'dur. TODO KAYNAK. Bu konu listesinin sonundaki konu ise bir muhabir veya haberi yazan kiÅŸinin kendi Ã¼rettiÄŸi ve Ã¶nceli konulardan baÄŸÄ±msÄ±z olan Ã¶zgÃ¼n haberlerdir. Bu haberler gerÃ§ekten de benzersiz ve Ã¶zel bir gÃ¶zlem ve akÄ±l yÃ¼rÃ¼tmeye dayalÄ± Ã¶zgÃ¼n bir karakter taÅŸÄ±maktadÄ±r. 

Ã–zgÃ¼n olanlar dÄ±ÅŸÄ±nda geri kalan haber konularÄ±nÄ±n sÃ¼rekli aynÄ± gÃ¼ndem etrafÄ±nda dolaÅŸÄ±yor olmasÄ± gÃ¶reli bir monotonluk algÄ±sÄ±na neden olabilir. Ã–rneÄŸin herhangi bir haber sitesinde kolayca gÃ¶rÃ¼lebilecek arama alanÄ±na "kar alarmÄ±" yazÄ±ldÄ±ÄŸÄ±nda ortaya Ã§Ä±kacak haberlerde deÄŸiÅŸen konular sadece kar alarmÄ±nÄ±n hangi bÃ¶lgeleri etkileyeceÄŸi ve tarihleridir.  Dikkatli bir okur gelecek yÄ±la ait kar alarmÄ± haberini daha o yÄ±l gelmeden metine dÃ¶kerek yazabilir. BÃ¶yle bir durumda haber olgusu artÄ±k Ã¶zgÃ¼nlÃ¼kten tamamen ayrÄ±lmÄ±ÅŸ herhangi dijital bir telefon hatÄ±rlatmasÄ± (push notification) farksÄ±z hale gelmektedir.  Ancak bunun aksine Ã¶zellikle TODO tarafÄ±ndan x haberdir -x haber deÄŸildir ÅŸeklinde Ã¶zetlenen tÃ¼rÃ¼ bir haber aynÄ± monotonluÄŸa sahip deÄŸildir. Ancak bu tÃ¼r haberler de tekrar edildikÃ§e daha az ilgi Ã§eker hale gelmektedir.  Ã–rneÄŸin "Facebook'un gÃ¼venlik aÃ§Ä±ÄŸÄ±nÄ± bulan TÃ¼rk genci" tÃ¼rÃ¼ haberler bu kategoridedir.  

Peki haberlere ait bu **monotonluk**, yani haberlerin hep benzer konular iÃ§eriyor olmasÄ± Ã¶lÃ§Ã¼lebilir mi? Ya da bir haberin monoton olduÄŸunu gÃ¶sterecek nesnel Ã¶lÃ§Ã¼tler var mÄ±? Bunu Ã¶lÃ§menin okuyarak deÄŸerlendirme dÄ±ÅŸÄ±nda bir alternatifi yokmuÅŸ gibi gÃ¶zÃ¼kebilir.

IDEA: OlasÄ± makale baÅŸlÄ±ÄŸÄ±: Kar AlarmÄ±: Haberler, hep aynÄ± konular mÄ±? Haber MonotonluÄŸunun Ã–lÃ§Ã¼lmesi

# 03.01.2020 - paper-localagenda-beingused

Anadolu'nun farklÄ± ÅŸehirleri ile ilgili olarak ulusal basÄ±nda Ã§Ä±kan haberlerin gÃ¼ndemi nedir? Bu Ã§alÄ±ÅŸma bu gÃ¼ndemi ortaya Ã§Ä±karmayÄ± amaÃ§lamaktadÄ±r. 81 ile ilgili sÃ¼rekli olarak aynÄ± anda yayÄ±nlanan haberlerin tamamÄ±nda ele alÄ±nan konular o ÅŸehirlerin hep aynÄ± Ã¶zelliklerine mi odaklanmaktadÄ±r yoksa Ã¶zgÃ¼n haberler mi Ã¼retilmektedir? YazÄ±lÄ± basÄ±n haber Ã¼retiminde Ã§eÅŸitli kalÄ±plar kullandÄ±ÄŸÄ±, haber yazarlarÄ±nÄ±n, basÄ±n aÃ§Ä±klamalarÄ±nÄ±n, olgularÄ±n ele alÄ±nÄ±ÅŸ ÅŸekillerinin haberlerle ilgili olarak bazÄ± kliÅŸeler barÄ±ndÄ±rdÄ±ÄŸÄ±, Ã¶zellikle sÃ¼rekli olarak haber Ã¼retilmesinden Ã¶tÃ¼rÃ¼ Ã¶zgÃ¼nlÃ¼ÄŸÃ¼n yerini gÃ¼ncel ve ilgi Ã§ekiciliÄŸe yÃ¶nlendirdiÄŸi, haberlerin ise bu yÃ¶ne evrildiÄŸi dÃ¼ÅŸÃ¼nÃ¼lmektedir. Bu dÃ¼ÅŸÃ¼nce bu araÅŸtÄ±rmanÄ±n test edilecek temel hipotezidir. Bu miktarda Ã§ok haberin neden bahsettiÄŸini anlamanÄ±n en hÄ±zlÄ± yolu haberlerin bir algoritma tarafÄ±ndan okunarak deÄŸerlendirilmesidir. Bu Ã§alÄ±ÅŸma kapsamÄ±nda geliÅŸtirilen algoritma ile TODO adet haber TODO adet kaynaktan elde edilerek bu analiz edilmiÅŸtir. Analiz haberlerin Ã¶zgÃ¼nlÃ¼k ve kliÅŸe olma karakterini ele alarak metinsel derinliÄŸi incelemektedir.  



